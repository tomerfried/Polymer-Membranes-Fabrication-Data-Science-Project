{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42b3dd94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import hex_rating as HR\n",
    "import pickle\n",
    "from numpy import asarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2188263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inital cleaning of german accents, special symbols, and unnecsseary columns\n",
    "data = pd.read_excel('initial data.xlsx', '50 kx')\n",
    "\n",
    "data.rename(columns={'IDProbe.L_semittel':'IDProbe.Loesemittel',\n",
    "                   'IDProbe.Pr_paration':'IDProbe.Preparation',\n",
    "                  'Vergrößerung':'Vergroesserung'}, inplace=True)\n",
    "\n",
    "data = data.filter(['IDProbe.Probennummer',\n",
    "           'IDProbe.Preparation',\n",
    "           'IDProbe.Loesemittel',\n",
    "          'IDProbe.Probeninforma1',\n",
    "           'Bildnummer',\n",
    "           'Detektor',\n",
    "           'Vergroesserung',\n",
    "            'Image_Pixel_S1',\n",
    "            \"Im_BitsPerPixel\",\n",
    "            \"Signal\",\n",
    "            'Header_Dump'\n",
    "          ])\n",
    "\n",
    "replace_dict = {'ü':'ue','ö':'oe','ä':'ae','μ':'u','µ':'u','\\n':'; ',\n",
    "                'PS88P4VP18':'PS82P4VP18','PS83,6P4VP16,8':'PS83,6P4VP16,4',\n",
    "                '_x000D_':'','°':''}\n",
    "\n",
    "for i in data.index:\n",
    "    for column_name in data.columns:\n",
    "        strng = data.at[i, column_name]\n",
    "        if type(strng) is str:\n",
    "            for origin, new in replace_dict.items():\n",
    "                    strng = strng.replace(origin,new)\n",
    "            data.at[i, column_name] = strng\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c09de0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits column 'IDProbe.Probeninforma1' and its information to many different independent columns\n",
    "def split_column(df, column_label, row_index):\n",
    "    \n",
    "    row_val = df.iloc[row_index][column_label]\n",
    "    \n",
    "    if not pd.isnull(row_val): \n",
    "        new_vals = row_val.split(';') # splits every row\n",
    "\n",
    "        nv_dict = {} #the keys represent new column names, the values represent new entries, all originated from 'IDProbe.Probeninforma1'\n",
    "        for elem in new_vals:\n",
    "            if ':' in elem:\n",
    "                key, value = elem.split(':',1)\n",
    "                nv_dict[key.strip()] = value.strip()\n",
    "            elif \"Recycled\" in elem:\n",
    "                nv_dict['Is Recycled'] = elem\n",
    "                \n",
    "\n",
    "        for key,value in nv_dict.items():\n",
    "            df.loc[row_index,key] = value\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2c77edc",
   "metadata": {},
   "outputs": [],
   "source": [
    " #execution of the function above\n",
    "for i in data.index:\n",
    "    split_column(data, 'IDProbe.Probeninforma1', i)\n",
    "    \n",
    "# labels that are interesting to add later, but have relatively few filled rows:\n",
    "#electric field, casting, bladegap, Luftfeuchtigkeit, Temperatur, \n",
    "#even later, temperaturbehandlung after crosslinking should be checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "660fbc88",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# checks if given data of image is compatible to requirements\n",
    "    \n",
    "properties = {\n",
    "    \"Image_Pixel_S1\":['2.233 nm'],\n",
    "    \"Vergroesserung\":[50,50.0],\n",
    "    \"Im_BitsPerPixel\":[8],\n",
    "    \"Detektor\":[\"InLens\"],\n",
    "    \"Signal\":[1.0],\n",
    "        }\n",
    "\n",
    "# checks every label and its value for each row in the data.\n",
    "# if value is not valid, the row is dropped out\n",
    "for index, row in data.iterrows():\n",
    "    for label_name, values in properties.items():\n",
    "        if row[label_name] not in values:\n",
    "            #print(row[\"Bildnummer\"]+\", \"+str(index)+\":\"+label_name+\":\"+str(row[label_name])+\" is not valid\")\n",
    "            data.drop(index, inplace=True)\n",
    "            break\n",
    "            \n",
    "data.drop(865, inplace=True) # deletes duplicated image in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf3cdd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some rows have 'Abdampfzeit N2' and 'Abdampfzeit in Air' instead of 'Abdampfzeit Air'\n",
    "#(we treat them as they're the same) therefore we transfer them to 'Abdampfzeit Air' and drop labels \n",
    "# of 'Abdampfzeit N2' and 'Abdampfzeit in Air'\n",
    "\n",
    "for i in data.index:\n",
    "    if not pd.isnull(data.at[i, 'Abdampfzeit N2']):\n",
    "        data.at[i, 'Abdampfzeit Air'] = data.at[i, 'Abdampfzeit N2']\n",
    "        \n",
    "for i in data.index:\n",
    "    if not pd.isnull(data.at[i, 'Abdampfzeit in Air']):\n",
    "        data.at[i, 'Abdampfzeit Air'] = data.at[i, 'Abdampfzeit in Air']\n",
    "        \n",
    "data.drop(columns = ['Abdampfzeit N2', 'Abdampfzeit in Air'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5220eddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some rows have values in 'Abdampfzeit E-Feld' and in 'Abdampfzeit Air' (we treat them as they're the same)\n",
    "# therefore the first one is added to the second one, respectively.\n",
    " \n",
    "for i in data.index:\n",
    "    \n",
    "    if not pd.isnull(data.at[i, 'Abdampfzeit E-Feld']) and data.at[i, 'Abdampfzeit E-Feld'] != '0s':\n",
    "        seconds_air = int(data.at[i, 'Abdampfzeit Air'].replace('s',''))\n",
    "        seconds_efeld = int(data.at[i, 'Abdampfzeit E-Feld'].replace('s',''))\n",
    "        seconds_air = seconds_air+seconds_efeld\n",
    "        data.at[i, 'Abdampfzeit Air'] = seconds_air"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "57231359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of non relevant columns\n",
    "data = data.filter([\n",
    "                    'Bildnummer',\n",
    "                    'Polymerkonzentration',\n",
    "                    'Loesemittel',\n",
    "                    'Abdampfzeit Air',\n",
    "                    'Zusammensetzung',\n",
    "                    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d991dd90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recognize_data(re_list,label_name):\n",
    "    # given regex list and column name, gets data from 'bildnummer' column and sets it in designated column.\n",
    "    # the alogrithm is based on matching every entry to regular expressions\n",
    "    # as theres a match, the entry is saved in a designated column\n",
    "    \n",
    "    data[label_name] = np.nan # creates an empty new column\n",
    "    \n",
    "    for i in data.index:\n",
    "        strng = data.at[i, 'Bildnummer']\n",
    "        for exp in re_list:\n",
    "            res = re.findall(exp, strng, re.IGNORECASE) # res stores the extracted data from 'bildnummer' column\n",
    "            \n",
    "            if res:\n",
    "                #print(label_name, res, [strng.replace(elem,'@@@') for elem in res])# usefull for residue check\n",
    "                data.loc[i, label_name] = res[0]\n",
    "                break\n",
    "                \n",
    "        # this part is dedicated to fill empty entries of 'ps_p4vp_ratio' and 'molec_weight'\n",
    "        # which have mathching values in 'Zusammensetzung' column\n",
    "        if label_name in ['ps_p4vp_ratio', 'molec_weight']:\n",
    "            if not pd.isnull(data.at[i, 'Zusammensetzung']) and pd.isnull(data.at[i, label_name]):\n",
    "                strng = data.at[i, 'Zusammensetzung']\n",
    "                for exp in re_list:\n",
    "                    res = re.findall(exp, strng, re.IGNORECASE)\n",
    "                    if res:\n",
    "                        data.at[i, label_name] = res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c80a5bb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the lists are regular expressions input patterns to the function above.\n",
    "# besides them, theres a line where the function is executed with them\n",
    "solution = [ r'THF_DMF_DOX_\\d+_\\d+_\\d+', r'\\d+DMF_\\d+THF_\\d+DOX',r'\\d+DMF_\\d+THF', r'\\d+DMF-\\d+THF', r'\\d+THF_\\d+DMF',\n",
    "            r'THF_DMF_\\d+_\\d+', r'DMF_THF_\\d+_\\d+', r'DMF-THF_\\d+-\\d+', r'DMF-THF_\\d+-\\d+', r'DMF\\d+-THF\\d+',\n",
    "            r'\\d+DOX_\\d+THF', r'DMF\\d+THF\\d+', r'THF\\d+DMF\\d+', r'\\d+D_\\d+T;', '100DOX','DOX100', 'D_T;', 'D_T',\n",
    "            '6-4','4-6','5-5', 'THF_DMF', 'DMF_THF', 'DMF;']\n",
    "\n",
    "recognize_data(solution,'solution')\n",
    "\n",
    "evap_air = [r'_\\d+sAir_', r'_\\d+sAir_',\n",
    "           r'_\\d+sec_', r'_\\d+sec_',r'_\\d+sec-', r'_\\d+sec-', \n",
    "            r'_\\d+s_', r'_\\d+s_', r'-\\d+s_', r'-\\d+s_', r'-\\d+s-', r'-\\d+s-', r'S\\d+s', r'S\\d+s', r'G\\d+s',\n",
    "            r'G\\d+s', r'S\\d+.\\d+s']\n",
    "\n",
    "recognize_data(evap_air,'evap_air')\n",
    "\n",
    "poly_concen = [r'_\\d+.\\d+ wt%_', r'\\d+wt%', r'\\d+.\\d+wt%',\n",
    "             r'\\d+ wt%', 'K(\\d+)-', r'_\\d+%_', r'_\\d+%_', r'_\\d+.\\d+%_', r'_\\d+%', r'-\\d+%-']\n",
    "                \n",
    "\n",
    "recognize_data(poly_concen,'poly_concen')\n",
    "\n",
    "ps_p4vp_ratio = [r'PS\\d+P4VP\\d+', r'PS\\d+.\\d+P4VP\\d+.\\d+', r'PS\\d+-P4VP\\d+', r'S\\d+VP\\d+', r'S\\d+VP\\d+',\n",
    "                r'PVBCB\\d+P4VP\\d+', r'PS\\d+.\\d+_P4VP\\d+.\\d+', r'PS\\d+_P4VP\\d+',r'PS-4VP\\d+',\n",
    "                 r'PVBCB\\d+-P4VP\\d+', r'\\d+P4VP\\d+', 'S\\d+_4VP\\d+', r'S\\d+VP', r'PS\\d+-b-P4VP\\d+',\n",
    "                 r'PSP4VP\\d+', r'SVP\\d+', r'\\d+PS, \\d+ P4VP']\n",
    "\n",
    "recognize_data(ps_p4vp_ratio,'ps_p4vp_ratio')\n",
    "\n",
    "molec_weight = ['98_0kV', r'\\d+k', r'-\\d+ ', r'-\\d+-', r'\\d+_0kV', r'-\\d+_recycle', '-154_', '_197_']\n",
    "\n",
    "recognize_data(molec_weight,'molec_weight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5b61581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every entry is strapped of non relevant characters in Polymerkonzentration and poly_concen columns\n",
    "def poly_concen_remover(label_name):\n",
    "    remove_list = ['%','-','_','wt', 'c', 'Wt']\n",
    "    for i in data.index:\n",
    "        if not pd.isnull(data.at[i, label_name]) and type(data.at[i, label_name]) is str:\n",
    "            for strng in remove_list:\n",
    "                data.at[i, label_name] = data.at[i, label_name].replace(strng,'')\n",
    "            data.at[i, label_name] = data.at[i, label_name].replace(',','.')\n",
    "            data.at[i, label_name] = float(data.at[i, label_name])\n",
    "\n",
    "poly_concen_remover('poly_concen')\n",
    "poly_concen_remover('Polymerkonzentration')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba2724c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every entry is strapped of non relevant characters in Abdampfzeit Air and evap_air columns\n",
    "def evap_air_remover(label_name):\n",
    "    remove_list = ['S','s', 'G', 'sAir', 'Air','ec', '_', '-', '>']\n",
    "    for i in data.index:\n",
    "        if not pd.isnull(data.at[i, label_name]) and type(data.at[i, label_name]) is str:\n",
    "            for strng in remove_list:\n",
    "                data.at[i, label_name] = str(data.at[i, label_name]).replace(strng,'')\n",
    "            data.at[i, label_name] = data.at[i, label_name].replace(',','.')\n",
    "            data.at[i, label_name] = float(data.at[i, label_name])\n",
    "            \n",
    "evap_air_remover('evap_air')\n",
    "evap_air_remover('Abdampfzeit Air')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5cf36f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every entry is strapped of non relevant characters in 'molec_weight' columnz\n",
    "remove_list = ['recycle', '_0kV', 'k', 'K', '_', '-','^']\n",
    "for i in data.index:\n",
    "    if not pd.isnull(data.at[i, 'molec_weight'])and type(data.at[i, 'molec_weight']) is str:\n",
    "        for strng in remove_list:\n",
    "            data.at[i, 'molec_weight'] = data.at[i, 'molec_weight'].replace(strng,'')\n",
    "        data.at[i, 'molec_weight'] = float(data.at[i, 'molec_weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc049db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fills empty entries, which their value was found after spliting 'bildnummer' column above\n",
    "\n",
    "# 'x_fill' are dataframes for eye-checking if extracted values are okay\n",
    "\n",
    "solution_fill = pd.DataFrame(columns = ['Bildnummer' ,'Polymerkonzentration' ,'Loesemittel' ,'Abdampfzeit Air' ,\n",
    "                                     'Zusammensetzung' ,'solution' ,'evap_air' ,'poly_concen' ,'ps_p4vp_ratio' ,\n",
    "                                     'molec_weight'])\n",
    "evap_air_fill = pd.DataFrame(columns = ['Bildnummer' ,'Polymerkonzentration' ,'Loesemittel' ,'Abdampfzeit Air' ,\n",
    "                                     'Zusammensetzung' ,'solution' ,'evap_air' ,'poly_concen' ,'ps_p4vp_ratio' ,\n",
    "                                     'molec_weight'])\n",
    "poly_concen_fill = pd.DataFrame(columns = ['Bildnummer' ,'Polymerkonzentration' ,'Loesemittel' ,'Abdampfzeit Air' ,\n",
    "                                     'Zusammensetzung' ,'solution' ,'evap_air' ,'poly_concen' ,'ps_p4vp_ratio' ,\n",
    "                                     'molec_weight'])\n",
    "\n",
    "\n",
    "for i in data.index:\n",
    "\n",
    "    if pd.isnull(data.at[i, 'Loesemittel']) and (not pd.isnull(data.at[i, 'solution'])):\n",
    "        row_dict = data.iloc[i].to_dict()\n",
    "        solution_fill = solution_fill.append(row_dict, ignore_index = True)\n",
    "        data.at[i, 'Loesemittel'] = data.at[i, 'solution']\n",
    "        \n",
    "    if pd.isnull(data.at[i, 'Abdampfzeit Air']) and (not pd.isnull(data.at[i, 'evap_air'])):\n",
    "        row_dict = data.iloc[i].to_dict()\n",
    "        evap_air_fill = evap_air_fill.append(row_dict, ignore_index = True)\n",
    "        data.at[i, 'Abdampfzeit Air'] = data.at[i, 'evap_air']\n",
    "        \n",
    "    if pd.isnull(data.at[i, 'Polymerkonzentration']) and (not pd.isnull(data.at[i, 'poly_concen'])):\n",
    "        row_dict = data.iloc[i].to_dict()\n",
    "        poly_concen_fill = poly_concen_fill.append(row_dict, ignore_index = True)\n",
    "        data.at[i, 'Polymerkonzentration'] = data.at[i, 'poly_concen']\n",
    "        \n",
    "#solution_fill.filter(['Bildnummer','solution']).to_csv('solution_fill.csv')\n",
    "#evap_air_fill.filter(['Bildnummer','evap_air']).to_csv('evap_air_fill.csv')\n",
    "#poly_concen_fill.filter(['Bildnummer','poly_concen']).to_csv('poly_concen_fill.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f51ab285",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code is devoted for eye-checking of human mistakes, mostly differences between information in 'Bildnummer'\n",
    "# and extracted data from 'Bildnummer' column\n",
    "\n",
    "evap_air_comparison = pd.DataFrame(columns = ['Bildnummer' ,'Polymerkonzentration' ,'Loesemittel' ,'Abdampfzeit Air' ,\n",
    "                                     'Zusammensetzung' ,'solution' ,'evap_air' ,'poly_concen' ,'ps_p4vp_ratio' ,\n",
    "                                     'molec_weight'])\n",
    "poly_concen_comparison = pd.DataFrame(columns = ['Bildnummer' ,'Polymerkonzentration' ,'Loesemittel' ,'Abdampfzeit Air' ,\n",
    "                                     'Zusammensetzung' ,'solution' ,'evap_air' ,'poly_concen' ,'ps_p4vp_ratio' ,\n",
    "                                     'molec_weight'])\n",
    "\n",
    "for i in data.index:     \n",
    "    if (not pd.isnull(data.at[i, 'Abdampfzeit Air'])) and (not pd.isnull(data.at[i, 'evap_air'])):\n",
    "        if data.at[i, 'Abdampfzeit Air'] != data.at[i, 'evap_air']:\n",
    "            row_dict = data.iloc[i].to_dict()\n",
    "            evap_air_comparison = evap_air_comparison.append(row_dict, ignore_index = True)\n",
    "\n",
    "    if (not pd.isnull(data.at[i, 'Polymerkonzentration'])) and (not pd.isnull(data.at[i, 'poly_concen'])):\n",
    "        if data.at[i, 'Polymerkonzentration'] != data.at[i, 'poly_concen']:\n",
    "            row_dict = data.iloc[i].to_dict()\n",
    "            poly_concen_comparison = evap_air_comparison.append(row_dict, ignore_index = True)\n",
    "\n",
    "\n",
    "#evap_air_comparison.filter(['Bildnummer','Abdampfzeit Air','evap_air']).to_csv('evap_air_comparison.csv')\n",
    "#poly_concen_comparison.filter(['Bildnummer','Polymerkonzentration','poly_concen']).to_csv('poly_concen_comparison.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1791e07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# completion of some missing data, which was collected manually\n",
    "complement_data = pd.read_csv('manually_added_missing.csv',index_col=0)\n",
    "\n",
    "for i, row in complement_data.iterrows():\n",
    "    \n",
    "    file_name = row[0]\n",
    "    index = data.loc[data['Bildnummer']==file_name].index[0]\n",
    "    \n",
    "    data.at[index, 'molec_weight'] = complement_data.at[i, 'molec_weight']\n",
    "    data.at[index, 'Abdampfzeit Air'] = complement_data.at[i, 'Abdampfzeit Air']\n",
    "    data.at[index, 'Loesemittel'] = complement_data.at[i, 'Loesemittel']\n",
    "    data.at[index, 'Polymerkonzentration'] = complement_data.at[i, 'Polymerkonzentration']\n",
    "\n",
    "# removal of rows with missing data which cant be filled\n",
    "missing_data = pd.read_csv('missing data.csv', index_col=0)\n",
    "for row in missing_data.iterrows():\n",
    "    file_name = row[1][0]\n",
    "    data = data[data['Bildnummer'] != file_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "2efde5d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every entry in 'ps_p4vp_ratio' is matched to a single form of entry: XX in 'PS4VP_[%]' column(XX is numbers)\n",
    "\n",
    "#patterns indices:\n",
    "                 #0-10\n",
    "remove_list = [r'(\\d+)PS. (\\d+) P4VP',r'PS(\\d+)P4VP(\\d+)', r'PS(\\d+.\\d+)P4VP(\\d+.\\d+)', r'PS(\\d+)-P4VP(\\d+)', r'S(\\d+)VP(\\d+)',\n",
    "                r'PVBCB(\\d+)P4VP(\\d+)', r'PS(\\d+.\\d+)_P4VP(\\d+.\\d+)', r'PS(\\d+)_P4VP(\\d+)',\n",
    "                 r'PVBCB(\\d+)-P4VP(\\d+)', r'(\\d+)P4VP(\\d+)', 'S(\\d+)_4VP(\\d+)',\n",
    "                 #11-15\n",
    "               r'PS(\\d+)-b-P4VP(\\d+)',r'PS-4VP(\\d+)',r'PSP4VP(\\d+)', r'SVP(\\d+)', r'(\\d+)PS, (\\d+) P4VP',\n",
    "                 #16\n",
    "               r'S(\\d+)VP']\n",
    "\n",
    "data['P4VP_[%]'] = np.nan\n",
    "\n",
    "for row in data.iterrows():\n",
    "    j = row[0] # just index of a row\n",
    "    if not pd.isnull(data.at[j, 'ps_p4vp_ratio']):\n",
    "        strng = data.at[j, 'ps_p4vp_ratio'].replace(',','.') # some filenames have ',' instead of '.' for decimal numbers\n",
    "        for i in range(len(remove_list)):\n",
    "            result = re.findall(remove_list[i], strng, re.IGNORECASE) # stores the extracted numbers from 'ps_p4vp_ratio' entries\n",
    "            if not result:\n",
    "                continue\n",
    "            else:\n",
    "                percentages = result[0]\n",
    "                \n",
    "                # i represents the index  of the right regular experssion pattern of the entry\n",
    "                # in the order of the patterns in 'remove_list'.\n",
    "                if type(percentages) is tuple: # if there two numbers in the entry, patterns indices 0-10\n",
    "                    per_ps_pvbcb, per_p4vp = percentages[0], percentages[1]\n",
    "                    data.at[j, 'P4VP_[%]'] = float(per_p4vp)\n",
    "                    break\n",
    "\n",
    "                else: # if there is a single number in the entry\n",
    "                    if i in [11,12, 13, 14, 15]:\n",
    "                        per_p4vp = percentages\n",
    "                    if i == 16:\n",
    "                        per_ps = percentages\n",
    "                        per_p4vp = str(100-int(per_ps))\n",
    "                    data.at[j, 'P4VP_[%]'] = float(per_p4vp)\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "c83126c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# every entry in 'Loesemittel' is matched to a single form of entry:\n",
    "#YY in 'DMF_[%]' column and YY in 'THF_[%]' column (YY are numbers)\n",
    "\n",
    "\n",
    "# patterns index:\n",
    "                 #0-9\n",
    "remove_list = [r'DMF(\\d+)-THF(\\d+.\\d+)-Dioxan(\\d+.\\d+)', r'DMF(\\d+)-THF(\\d+)-Dioxan(\\d+)', r'(\\d+)DMF-(\\d+)THF-(\\d+)Dioxan', r'DMF/THF/Dioxan (\\d+)/(\\d+)/(\\d+)',\n",
    "               r'(\\d+)THF-(\\d+)DMF-(\\d+)Dioxan', r'(\\d+)THF/(\\d+)DMF/(\\d+)Dioxan', r'THF/DMF/Dioxan : (\\d+)/(\\d+)/(\\d+)',\n",
    "                r'(\\d+) THF/ (\\d+) DMF/ (\\d+) Dioxan', r'THF_DMF_DOX_(\\d+)_(\\d+)_(\\d+)',\n",
    "               r'DMF(\\d+)-Dioxan(\\d+)-THF(\\d+)',\n",
    "                #10-23\n",
    "               r'(\\d+)DMF_(\\d+)THF', r'(\\d+)DMF-(\\d+)THF', r'DMF(\\d+)THF(\\d+)',r'(\\d+)DMF/(\\d+)THF',\n",
    "               r'DMF(\\d+)/THF(\\d+)', r'DMF(\\d+)-THF(\\d+)', r'(\\d+)DMF-THF(\\d+)', r'DMF/THF (\\d+)/(\\d+)',\n",
    "               r'THF(\\d+)-DMF(\\d+)', r'(\\d+)THF-(\\d+)DMF', r'(\\d+) THF/ (\\d+) DMF',\n",
    "                r'THF/DMF : (\\d+)/(\\d+)', r'THF/DMF, (\\d+):(\\d+)', r'(\\d+)THF/(\\d+)DMF',\n",
    "                #24-25\n",
    "                'THF-DMF', 'THF/DMF',\n",
    "                #26\n",
    "               r'DOX(\\d+)/THF(\\d+)',\n",
    "                #27\n",
    "               'DMF',\n",
    "                #28-29\n",
    "               '100DOX','Dioxan']\n",
    "\n",
    "data['DMF_[%]'], data['THF_[%]'] = 0, 0\n",
    "# outer loop - extracts  and fixes numbers from 'Loesemittel' entries\n",
    "# inner loop - saves the numbers in a designated column\n",
    "for row in data.iterrows():\n",
    "    j = row[0]\n",
    "    if not pd.isnull(data.at[j, 'Loesemittel']):\n",
    "        \n",
    "        strng = data.at[j, 'Loesemittel'].replace(',','.')\n",
    "\n",
    "        percents = re.findall(r'\\d+', strng, re.IGNORECASE)\n",
    "\n",
    "        if len(percents) == 2: # if there are two numbers in the entry\n",
    "            if len(percents[0])==1 and len(percents[1])==1:\n",
    "                if percents[0] == '1' and percents[1] == '1':\n",
    "                    fix_per1, fix_per2 = '50', '50'\n",
    "                elif percents[0] == '2' and percents[1] == '3':\n",
    "                    fix_per1, fix_per2 = '40', '60'\n",
    "                elif percents[0] == '3' and percents[1] == '2':\n",
    "                    fix_per1, fix_per2 = '60', '40'\n",
    "                else:\n",
    "                    fix_per1, fix_per2 = percents[0]+'0', percents[1]+'0' # some entries are just to be filled with another zero\n",
    "                strng = strng.replace(percents[0],fix_per1)\n",
    "                if percents[0] != '1' and percents[0] != '5':\n",
    "                    strng = strng.replace(percents[1],fix_per2)\n",
    "\n",
    "        if len(percents) == 3: # if there are three numbers in the entry\n",
    "            if len(percents[0]) == 1 and len(percents[1]) == 1 and len(percents[2]) == 1:\n",
    "                fix_per1, fix_per2, fix_per3 = percents[0]+'0', percents[1]+'0', percents[2]+'0'\n",
    "                strng = strng.replace(percents[0],fix_per1)\n",
    "                strng = strng.replace(percents[1],fix_per2)\n",
    "                \n",
    "        for i in range(len(remove_list)):\n",
    "            result = re.findall(remove_list[i], strng, re.IGNORECASE)\n",
    "            if result:\n",
    "                # i represents the index  of the right regular experssion pattern of the entry\n",
    "                # in the order of the patterns in 'remove_list'.\n",
    "                if 0<=i<=9:\n",
    "                    if 0<=i<=3:\n",
    "                        dmf_per, thf_per, dox_per = result[0][0], result[0][1], result[0][2]\n",
    "                    if 4<=i<=8:\n",
    "                        thf_per, dmf_per, dox_per = result[0][0], result[0][1], result[0][2]\n",
    "                    if i==9:\n",
    "                        dmf_per, dox_per, thf_per = result[0][0], result[0][1], result[0][2]\n",
    "                    data.at[j, 'DMF_[%]'], data.at[j, 'THF_[%]'] = float(dmf_per), float(thf_per)\n",
    "                  \n",
    "                \n",
    "                if 10<=i<=23:\n",
    "                    if 10<=i<=17:\n",
    "                        dmf_per, thf_per = result[0][0], result[0][1]\n",
    "                    if 18<=i<=23:\n",
    "                        thf_per, dmf_per = result[0][0], result[0][1]\n",
    "                    data.at[j, 'DMF_[%]'], data.at[j, 'THF_[%]'] = float(dmf_per), float(thf_per)\n",
    "                    \n",
    "                if 24<=i<=25:\n",
    "                    thf_per, dmf_per = str(50), str(50)\n",
    "                    data.at[j, 'DMF_[%]'], data.at[j, 'THF_[%]'] = float(dmf_per), float(thf_per)\n",
    "                \n",
    "                if i==26:\n",
    "                    dox_per, thf_per = result[0][0], result[0][1]\n",
    "                    data.at[j, 'THF_[%]'] = float(thf_per)\n",
    "                    \n",
    "                if i == 27:\n",
    "                    dmf_per = str(100)\n",
    "                    data.at[j, 'DMF_[%]'] = float(dmf_per)\n",
    "                    \n",
    "                if 28<=i<=30:\n",
    "                    pass # no action beacuase 0 thf and 0 dmf menas 100 dox\n",
    "                    \n",
    "                break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "d1aca80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting rid of temporary used columns\n",
    "data.drop(columns = ['Zusammensetzung', 'solution', 'evap_air', 'poly_concen',\n",
    "                    'Loesemittel', 'ps_p4vp_ratio'], inplace = True)\n",
    "# converting string written numbers to floats\n",
    "for label in ['Polymerkonzentration', 'Abdampfzeit Air', 'molec_weight']:\n",
    "    data[label] = pd.to_numeric(data[label], downcast=\"float\")\n",
    "# renaming column names\n",
    "data.rename(columns={'Polymerkonzentration': 'Polymer_Concentration_[%]','Abdampfzeit Air': 'Evaporation_Time_[s]',\n",
    "                     'molec_weight': 'Molecular_Weight_[k]', 'Bildnummer': 'File_name'}, inplace=True)\n",
    "# and finally saving the processed data\n",
    "data.to_csv('processed_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd0ad04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyimagej",
   "language": "python",
   "name": "pyimagej"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
